#!/usr/bin/env python3
"""
Lightweight Flask API for serving river data to ESP32/IoT devices
Reads from the gauges.json file generated by usgs_multi_alert.py
Also serves the static HTML dashboard on the main page
"""

from flask import Flask, jsonify, request, send_from_directory, send_file
import json
import os
from datetime import datetime

# Optional CORS support
try:
    from flask_cors import CORS
    cors_available = True
except ImportError:
    cors_available = False
    print("Warning: flask-cors not installed. CORS will not be enabled.")

# TVA History database (for long-term historical charts)
try:
    from tva_history import get_observations, get_stats, get_date_range, get_observation_count
    tva_history_available = True
except ImportError:
    tva_history_available = False
    print("Note: TVA history module not available. Historical charts will be disabled.")

app = Flask(__name__)

if cors_available:
    CORS(app)  # Enable CORS for all routes

# Path to static site files
SITE_DIR = os.environ.get('SITE_DIR', '/site')

# Path to the generated gauges.json file
# Try multiple paths for local dev vs container
GAUGES_JSON_PATHS = [
    "/site/gauges.json",                                           # Container path
    "/chanslor/mdc/YOUTUBE/chanslor-usgs-river-levels/docker/usgs-site/gauges.json",  # Local dev path
    "usgs-site/gauges.json"                                        # Relative path
]

def get_gauges_json_path():
    """Find the first existing gauges.json file"""
    for path in GAUGES_JSON_PATHS:
        if os.path.exists(path):
            return path
    return None

GAUGES_JSON_PATH = get_gauges_json_path()

def load_gauges_data():
    """Load and parse the gauges.json file"""
    try:
        if not os.path.exists(GAUGES_JSON_PATH):
            return None

        with open(GAUGES_JSON_PATH, 'r') as f:
            return json.load(f)
    except Exception as e:
        print(f"Error loading gauges data: {e}")
        return None

def format_for_display(site_data):
    """
    Format site data for ESP32 OLED display
    Returns a compact format optimized for the 5-line display
    """
    name = site_data.get('name', 'Unknown')
    cfs = site_data.get('cfs')
    stage_ft = site_data.get('stage_ft')
    trend = site_data.get('trend_8h', 'unknown')

    # QPF data (precipitation forecast)
    qpf = site_data.get('qpf', {})
    qpf_dates = sorted(qpf.keys())
    qpf_today = qpf.get(qpf_dates[0], 0.0) if len(qpf_dates) > 0 else 0.0
    qpf_tomorrow = qpf.get(qpf_dates[1], 0.0) if len(qpf_dates) > 1 else 0.0
    qpf_day3 = qpf.get(qpf_dates[2], 0.0) if len(qpf_dates) > 2 else 0.0

    # Weather observations
    obs = site_data.get('obs') or {}
    temp_f = obs.get('temp_f')
    wind_mph = obs.get('wind_mph', 0.0)
    wind_dir = obs.get('wind_dir', 'N')

    # Determine flow status
    if cfs is not None:
        threshold_cfs = site_data.get('threshold_cfs')
        if threshold_cfs and cfs >= threshold_cfs:
            flow_status = f">= {cfs:.0f} cfs"
        else:
            flow_status = f"{cfs:.0f} cfs"
    else:
        flow_status = "N/A"

    # Trend arrow
    trend_arrow = "->"
    if trend == "rising":
        trend_arrow = "^"
    elif trend == "falling":
        trend_arrow = "v"

    return {
        "site_id": site_data.get('site'),
        "name": name,
        "flow": flow_status,
        "trend": f"{trend_arrow} {trend}",
        "stage_ft": stage_ft,
        "cfs": cfs,
        "thresholds": {
            "min_ft": site_data.get('threshold_ft'),
            "min_cfs": site_data.get('threshold_cfs'),
            "good_ft": site_data.get('good_ft'),
            "good_cfs": site_data.get('good_cfs')
        },
        "qpf": {
            "today": qpf_today,
            "tomorrow": qpf_tomorrow,
            "day3": qpf_day3
        },
        "weather": {
            "temp_f": temp_f,
            "wind_mph": wind_mph,
            "wind_dir": wind_dir
        },
        "timestamp": site_data.get('ts_iso'),
        "in_range": site_data.get('in_range', False),

        # Formatted strings for ESP32 display (5 lines)
        "display_lines": [
            f"{name}",
            f"{flow_status} {trend_arrow} {trend}",
            f"QPF Today: {qpf_today:.2f}\"",
            f"Tom:{qpf_tomorrow:.2f}\" Day3:{qpf_day3:.2f}\"",
            f"Max:{temp_f:.0f}F Wind:{wind_mph:.1f} {wind_dir}" if (temp_f is not None and wind_mph is not None and wind_dir) else "Weather: N/A"
        ]
    }

@app.route('/api/health', methods=['GET'])
def health():
    """Health check endpoint"""
    return jsonify({
        "status": "ok",
        "timestamp": datetime.utcnow().isoformat() + "Z"
    })

@app.route('/api/river-levels', methods=['GET'])
def get_all_river_levels():
    """
    Get all river levels
    Returns data for all monitored sites
    """
    data = load_gauges_data()

    if not data:
        return jsonify({
            "error": "Data not available",
            "message": "Unable to load river data. Background worker may not be running."
        }), 503

    sites = data.get('sites', [])
    formatted_sites = [format_for_display(site) for site in sites]

    return jsonify({
        "generated_at": data.get('generated_at'),
        "site_count": len(formatted_sites),
        "sites": formatted_sites
    })

@app.route('/api/river-levels/<site_id>', methods=['GET'])
def get_river_level(site_id):
    """
    Get data for a specific site
    Example: /api/river-levels/02399200 (Little River)
    """
    data = load_gauges_data()

    if not data:
        return jsonify({
            "error": "Data not available",
            "message": "Unable to load river data"
        }), 503

    # Find the requested site
    sites = data.get('sites', [])
    site_data = next((s for s in sites if s.get('site') == site_id), None)

    if not site_data:
        return jsonify({
            "error": "Site not found",
            "message": f"No data available for site {site_id}",
            "available_sites": [s.get('site') for s in sites]
        }), 404

    return jsonify(format_for_display(site_data))

@app.route('/api/river-levels/name/<name>', methods=['GET'])
def get_river_level_by_name(name):
    """
    Get data for a specific site by name (case-insensitive partial match)
    Example: /api/river-levels/name/little (matches "Little River")
    """
    data = load_gauges_data()

    if not data:
        return jsonify({
            "error": "Data not available"
        }), 503

    # Find site by name (case-insensitive partial match)
    sites = data.get('sites', [])
    name_lower = name.lower()
    site_data = next(
        (s for s in sites if name_lower in s.get('name', '').lower()),
        None
    )

    if not site_data:
        return jsonify({
            "error": "Site not found",
            "message": f"No site matching '{name}'",
            "available_sites": [{"id": s.get('site'), "name": s.get('name')} for s in sites]
        }), 404

    return jsonify(format_for_display(site_data))

@app.route('/')
def index():
    """Serve the main dashboard HTML"""
    index_path = os.path.join(SITE_DIR, 'index.html')
    if os.path.exists(index_path):
        return send_file(index_path)
    else:
        return "<h1>River Monitor Starting...</h1><p>Please wait while initial data loads...</p>", 503

@app.route('/gauges.json')
def gauges_json():
    """Serve the gauges data JSON"""
    json_path = os.path.join(SITE_DIR, 'gauges.json')
    if os.path.exists(json_path):
        return send_file(json_path, mimetype='application/json')
    else:
        return jsonify({"loading": True}), 503

@app.route('/details/<path:filename>')
def details(filename):
    """Serve detail pages"""
    details_dir = os.path.join(SITE_DIR, 'details')
    return send_from_directory(details_dir, filename)

@app.route('/api/predictions', methods=['GET'])
def get_predictions():
    """
    Get river predictions based on QPF forecast and historical patterns.
    Returns likelihood and timing estimates for each monitored river.
    """
    data = load_gauges_data()

    if not data:
        return jsonify({
            "error": "Data not available",
            "message": "Unable to load river data"
        }), 503

    predictions = data.get('predictions', [])

    if not predictions:
        return jsonify({
            "message": "No predictions available",
            "note": "Predictions are generated when QPF data is available"
        }), 200

    return jsonify({
        "generated_at": data.get('generated_at'),
        "prediction_count": len(predictions),
        "predictions": predictions
    })


@app.route('/api/usgs-history/<site_id>', methods=['GET'])
def get_usgs_history(site_id):
    """
    Get historical USGS data for charting.

    Query Parameters:
        days: Number of days of history (default: 7, max: 365)

    Example: /api/usgs-history/02341460?days=30

    Returns time series data for:
        - cfs (discharge)
        - feet (gage height)
    """
    import urllib.request
    import urllib.parse
    from datetime import timezone, timedelta

    days = request.args.get('days', 7, type=int)
    days = min(max(days, 1), 365)  # Clamp between 1 and 365

    end_date = datetime.now(timezone.utc)
    start_date = end_date - timedelta(days=days)

    # Build USGS API request
    params = {
        "sites": site_id,
        "parameterCd": "00060,00065",  # CFS and gage height
        "startDT": start_date.strftime("%Y-%m-%dT%H:%M:%S.000Z"),
        "endDT": end_date.strftime("%Y-%m-%dT%H:%M:%S.000Z"),
        "siteStatus": "all",
        "format": "json"
    }

    url = f"https://waterservices.usgs.gov/nwis/iv/?{urllib.parse.urlencode(params)}"

    try:
        with urllib.request.urlopen(url, timeout=60) as response:
            data = json.loads(response.read())

        time_series = data.get("value", {}).get("timeSeries", [])

        # Parse CFS and feet data
        cfs_data = []
        feet_data = []

        for ts in time_series:
            var_code = ts.get("variable", {}).get("variableCode", [{}])[0].get("value", "")
            values = ts.get("values", [{}])[0].get("value", [])

            for item in values:
                dt_str = item.get("dateTime")
                val_str = item.get("value")

                if dt_str and val_str:
                    try:
                        val = float(val_str)
                        if var_code == "00060":  # CFS
                            cfs_data.append({"timestamp": dt_str, "value": val})
                        elif var_code == "00065":  # Feet
                            feet_data.append({"timestamp": dt_str, "value": val})
                    except (ValueError, TypeError):
                        continue

        # Calculate stats
        cfs_values = [d["value"] for d in cfs_data]
        feet_values = [d["value"] for d in feet_data]

        stats = {}
        if cfs_values:
            stats["cfs"] = {
                "min": min(cfs_values),
                "max": max(cfs_values),
                "avg": sum(cfs_values) / len(cfs_values)
            }
        if feet_values:
            stats["feet"] = {
                "min": min(feet_values),
                "max": max(feet_values),
                "avg": sum(feet_values) / len(feet_values)
            }

        # Downsample for large date ranges
        def downsample(data_list, target_points=200):
            if len(data_list) <= target_points:
                return data_list
            step = len(data_list) // target_points
            return [data_list[i] for i in range(0, len(data_list), step)][:target_points]

        return jsonify({
            "site_id": site_id,
            "days_requested": days,
            "cfs_count": len(cfs_data),
            "feet_count": len(feet_data),
            "stats": stats,
            "cfs": downsample(cfs_data),
            "feet": downsample(feet_data)
        })

    except Exception as e:
        return jsonify({
            "error": "Failed to fetch USGS data",
            "message": str(e)
        }), 503


@app.route('/api/tva-history/<site_code>', methods=['GET'])
def get_tva_history(site_code):
    """
    Get historical TVA dam data for charting.

    Query Parameters:
        days: Number of days of history (default: 7, max: 365)

    Example: /api/tva-history/HADT1?days=30

    Returns time series data for:
        - discharge_cfs (Release)
        - pool_elevation_ft (Lake Level)
        - tailwater_ft (Tailwater)
    """
    if not tva_history_available:
        return jsonify({
            "error": "TVA history not available",
            "message": "Historical data storage is not configured"
        }), 503

    # Get query parameters
    days = request.args.get('days', 7, type=int)
    days = min(max(days, 1), 365)  # Clamp between 1 and 365

    # Get observations
    observations = get_observations(site_code.upper(), days=days)

    if not observations:
        return jsonify({
            "site_code": site_code.upper(),
            "days": days,
            "observation_count": 0,
            "message": "No historical data available yet. Data will accumulate over time.",
            "observations": []
        }), 200

    # Get additional stats
    stats = get_stats(site_code.upper(), days=days)
    date_range = get_date_range(site_code.upper())

    return jsonify({
        "site_code": site_code.upper(),
        "days_requested": days,
        "observation_count": len(observations),
        "date_range": date_range,
        "stats": stats,
        "observations": observations
    })


@app.route('/api/tva-history/<site_code>/stats', methods=['GET'])
def get_tva_stats(site_code):
    """
    Get statistics for TVA dam data.

    Query Parameters:
        days: Number of days to analyze (default: 30)

    Example: /api/tva-history/HADT1/stats?days=90
    """
    if not tva_history_available:
        return jsonify({
            "error": "TVA history not available"
        }), 503

    days = request.args.get('days', 30, type=int)
    days = min(max(days, 1), 365)

    stats = get_stats(site_code.upper(), days=days)
    date_range = get_date_range(site_code.upper())
    total_count = get_observation_count(site_code.upper())

    return jsonify({
        "site_code": site_code.upper(),
        "days_analyzed": days,
        "total_observations": total_count,
        "date_range": date_range,
        "stats": stats
    })


@app.route('/api/tva-history/ocoee/combined', methods=['GET'])
def get_ocoee_combined_history():
    """
    Get combined historical data for all 3 Ocoee dams for cascade correlation charting.

    Query Parameters:
        days: Number of days of history (default: 7, max: 365)

    Example: /api/tva-history/ocoee/combined?days=30

    Returns combined time series for:
        - OCCT1 (Ocoee #3 - Upper) - top of mountain
        - OCBT1 (Ocoee #2 - Middle)
        - OCAT1 (Ocoee #1 - Lower/Parksville) - bottom

    Water cascades: Upper (#3) -> Middle (#2) -> Lower (#1)
    """
    if not tva_history_available:
        return jsonify({
            "error": "TVA history not available",
            "message": "Historical data storage is not configured"
        }), 503

    days = request.args.get('days', 7, type=int)
    days = min(max(days, 1), 365)

    # Ocoee sites configuration
    ocoee_sites = {
        "OCCT1": {"name": "Ocoee #3 (Upper)", "position": 1, "color": "#ef4444"},
        "OCBT1": {"name": "Ocoee #2 (Middle)", "position": 2, "color": "#eab308"},
        "OCAT1": {"name": "Ocoee #1 (Lower)", "position": 3, "color": "#22c55e"}
    }

    combined_data = {}
    overall_earliest = None
    overall_latest = None

    for site_code, config in ocoee_sites.items():
        observations = get_observations(site_code, days=days)
        stats = get_stats(site_code, days=days)
        date_range = get_date_range(site_code)

        combined_data[site_code] = {
            "name": config["name"],
            "position": config["position"],
            "color": config["color"],
            "observation_count": len(observations),
            "observations": observations,
            "stats": stats,
            "date_range": date_range
        }

        # Track overall date range
        if date_range.get("earliest"):
            if overall_earliest is None or date_range["earliest"] < overall_earliest:
                overall_earliest = date_range["earliest"]
        if date_range.get("latest"):
            if overall_latest is None or date_range["latest"] > overall_latest:
                overall_latest = date_range["latest"]

    return jsonify({
        "days_requested": days,
        "description": "All 3 Ocoee dams - Water flows: Upper (#3) -> Middle (#2) -> Lower (#1)",
        "date_range": {
            "earliest": overall_earliest,
            "latest": overall_latest
        },
        "sites": combined_data
    })


@app.route('/api')
def api_info():
    """API documentation endpoint"""
    return jsonify({
        "name": "USGS River Levels API",
        "version": "1.4",
        "dashboard": "/",
        "endpoints": {
            "health": "/api/health",
            "all_rivers": "/api/river-levels",
            "by_site_id": "/api/river-levels/{site_id}",
            "by_name": "/api/river-levels/name/{name}",
            "predictions": "/api/predictions",
            "usgs_history": "/api/usgs-history/{site_id}?days=7",
            "tva_history": "/api/tva-history/{site_code}?days=7",
            "tva_stats": "/api/tva-history/{site_code}/stats?days=30",
            "ocoee_combined": "/api/tva-history/ocoee/combined?days=7"
        },
        "examples": {
            "little_river": "/api/river-levels/02399200",
            "little_river_by_name": "/api/river-levels/name/little",
            "locust_fork": "/api/river-levels/02455000",
            "predictions": "/api/predictions",
            "rush_south_history_7d": "/api/usgs-history/02341460?days=7",
            "rush_south_history_30d": "/api/usgs-history/02341460?days=30",
            "hiwassee_history_7d": "/api/tva-history/HADT1?days=7",
            "hiwassee_history_30d": "/api/tva-history/HADT1?days=30",
            "hiwassee_stats": "/api/tva-history/HADT1/stats?days=90",
            "ocoee_combined_7d": "/api/tva-history/ocoee/combined?days=7",
            "ocoee_combined_30d": "/api/tva-history/ocoee/combined?days=30"
        },
        "new_features": {
            "predictions": "River predictions based on QPF forecast and 90-day historical response patterns",
            "usgs_history": "Historical USGS data with 7d/30d/90d/1yr time range options",
            "tva_history": "Long-term historical data for TVA dam sites (Hiwassee Dries)",
            "ocoee_combined": "Combined Ocoee dam cascade data showing all 3 dams for correlation analysis"
        }
    })

if __name__ == '__main__':
    # Run on port 8080 to match the existing configuration (or PORT env var)
    port = int(os.environ.get('PORT', 8080))
    app.run(host='0.0.0.0', port=port, debug=False)
